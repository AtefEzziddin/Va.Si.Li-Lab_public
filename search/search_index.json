{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Va.Si.Li-Lab","text":""},{"location":"#description","title":"Description","text":"<p>a VR-Lab for Simulation-based Learning.</p>"},{"location":"#disclaimer","title":"Disclaimer","text":"<p>This documentation is work in progress.</p> <p>And not all functions discribed here are implemented yet.</p>"},{"location":"#team","title":"Team","text":"<ul> <li>Prof. Dr. Alexander Mehler (Leader)  </li> <li>Giuseppe Abrami  </li> <li>Mevl\u00fct Bagci  </li> <li>Dr. Alexander Henlein  </li> <li>Patrick Schrottenbacher  </li> <li>Atef Ezziddin  </li> <li>Christian Spiekermann  </li> </ul>"},{"location":"#citation","title":"Citation","text":"<p>Please see the publications for further details.</p>"},{"location":"#task-list","title":"Task List","text":"<ul> <li> Init Documentation</li> <li> Current Documentation State<ul> <li> Home</li> <li> Getting Started</li> <li> Other Functions</li> <li> Replay Experiment</li> <li> Bots</li> <li> Scenarios</li> <li> Server Structure</li> <li> Projects</li> <li> Publications</li> </ul> </li> </ul>"},{"location":"publications/","title":"Publications","text":""},{"location":"publications/#publications","title":"Publications","text":""},{"location":"publications/#a-multimodal-data-model-for-simulation-based-learning-with-vasili-lab","title":"A Multimodal Data Model for Simulation-Based Learning with Va.Si.Li-Lab","text":"<p><pre><code>@inproceedings{Mehler:et:al:2023:a,\n  author    = {Mehler, Alexander and Bagci, Mevl{\\\"u}t and Henlein, Alexander\n               and Abrami, Giuseppe and Spiekermann, Christian and Schrottenbacher, Patrick\n               and Konca, Maxim and L{\\\"u}cking, Andy and Engel, Juliane and Quintino, Marc\n               and Schreiber, Jakob and Saukel, Kevin and Zlatkin-Troitschanskaia, Olga},\n  address   = {Cham},\n  booktitle = {Digital Human Modeling and Applications in Health, Safety, Ergonomics and Risk Management},\n  editor    = {Duffy, Vincent G.},\n  isbn      = {978-3-031-35741-1},\n  pages     = {539--565},\n  publisher = {Springer Nature Switzerland},\n  title     = {A Multimodal Data Model for Simulation-Based Learning with Va.Si.Li-Lab},\n  year      = {2023},\n  doi       = {10.1007/978-3-031-35741-1_39}\n}\n</code></pre> [Link] [RG]</p>"},{"location":"publications/#vasili-lab-as-a-collaborative-multi-user-annotation-tool-in-virtual-reality-and-its-potential-fields-of-application","title":"Va.Si.Li-Lab as a Collaborative Multi-User Annotation Tool in Virtual Reality and Its Potential Fields of Application","text":"<p><pre><code>@inproceedings{Abrami:et:al:2023,\n  author    = {Abrami, Giuseppe and Mehler, Alexander and Bagci, Mevl\\\"{u}t and Schrottenbacher, Patrick\n               and Henlein, Alexander and Spiekermann, Christian and Engel, Juliane\n               and Schreiber, Jakob},\n  title     = {Va.Si.Li-Lab as a Collaborative Multi-User Annotation Tool in\n               Virtual Reality and Its Potential Fields of Application},\n  year      = {2023},\n  isbn      = {9798400702327},\n  publisher = {Association for Computing Machinery},\n  address   = {New York, NY, USA},\n  url       = {https://doi.org/10.1145/3603163.3609076},\n  doi       = {10.1145/3603163.3609076},\n  booktitle = {Proceedings of the 34th ACM Conference on Hypertext and Social Media},\n  articleno = {22},\n  numpages  = {9},\n  location  = {Rome, Italy},\n  series    = {HT '23}\n}\n</code></pre> [Link] [pdf] [RG]</p>"},{"location":"publications/#presentations-posters","title":"Presentations / Posters","text":""},{"location":"publications/#towards-grounding-multimodal-semantics-in-interaction-data-with-vasili-lab","title":"Towards grounding multimodal semantics in interaction data with Va.Si.Li-Lab","text":"<p><pre><code>@inproceedings{Henlein:et:al:2023c,\n  title     = {Towards grounding multimodal semantics in interaction data with Va.Si.Li-Lab},\n  author    = {Henlein, Alexander and L\u00fccking, Andy and Bagci, Mevl\u00fct and Mehler, Alexander},\n  booktitle = {Proceedings of the 8th Conference on Gesture and Speech in Interaction (GESPIN)},\n  location  = {Nijmegen, Netherlands},\n  year      = {2023},\n  keywords  = {vasililab},\n  pdf       = {https://www.gespin2023.nl/documents/talks_and_posters/GeSpIn_2023_papers/GeSpIn_2023_paper_1692.pdf}\n}\n</code></pre> [pdf]</p>"},{"location":"getting_started/adding_scenes/","title":"Adding Scenes","text":"<p>To connect a scene via MetaStart,  you must first add the scene to the Unity project and then to the MongoDB database.</p>"},{"location":"getting_started/adding_scenes/#add-scene-in-unity","title":"Add Scene in Unity","text":""},{"location":"getting_started/adding_scenes/#create-a-new-scene","title":"Create a new Scene","text":"<ul> <li>Scenes are placed in the <code>Assets/Local/Scenes</code> folder. </li> <li>Right-click in the <code>Assets/Local/Scenes</code> folder and select <code>Create &gt; Scene</code>.</li> <li>Add and activate scene in the build settings <code>File/Build Setting &gt; Add Open Scene</code>.</li> </ul>"},{"location":"getting_started/adding_scenes/#debug-scene-without-metastart","title":"Debug Scene without MetaStart","text":"<p>Add the following prefabs: <code>Social Network Scene</code>, <code>MetaPlayer</code>, <code>AvatarSdkManagerHorizon</code> to the scene. (Not testet. <code>Social Network Scene</code> e.g. is not nessessary for the scene to work.)</p>"},{"location":"getting_started/adding_scenes/#add-scene-to-mongodb","title":"Add Scene to MongoDB","text":"<p>The Scene must be added to the MongoDB database to be accessible via MetaStart. As a student, please ask your coresponding supervisor to add the scene to the database. The scenes need to be added to <code>Experiment/scenarios-languages</code>. The .json structure is as follow:</p> Parameter Explanation<pre><code>{\n  \"name\": Name of the Scene in the scene selector,\n  \"internalName\": Name of the Scene in Unity,\n  \"roles\": Roles in the Scenario. Currently supporting english and german\n    {\n      \"name\": Name of the Role,\n      \"description\": Description of the Role,\n      \"spawnPosition\": Spawn Position of the Role,\n      \"mode\": Mode of the Role (player, observer),\n      \"maxCount\": Maximum Count of the Role,\n      \"admin\": Admin Role (start and ending levels),\n      \"level\": Level Descriptions for that role\n    },\n    \"level\": Levels in the Scenario,\n      {\n        \"id\": ID of the Level,\n        \"delay\": Delay of the Level (stops the level after n minutes; null if no delay)\n      },\n    \"enable\": Visible via MetaStart,\n    \"amountPlayersRequired\": Amount of Players Required, until admin can start the scenario\n}\n</code></pre> Example Scene Entry<pre><code>{\n  \"name\": \"Praktikum Experiment 3\",\n  \"shortName\": \"Praktikum 3\",\n  \"author\": \"Alexander Henlein\",\n  \"internalName\": \"PraktikumScenario03\",\n  \"roles\": {\n    \"DE\": [\n      {\n        \"name\": \"Person 1\",\n        \"description\": [\n          {\n            \"id\": 1,\n            \"description\": \"Rundfahrt erkl\u00e4ren\"\n          }\n        ],\n        \"spawnPosition\": \"P1\",\n        \"mode\": \"player\",\n        \"maxCount\": 1,\n        \"admin\": true,\n        \"level\": [\n          {\n            \"id\": 1,\n            \"description\": \"Rundfahrt\"\n          },\n          {\n            \"id\": 2,\n            \"description\": \"Erkl\u00e4ren\"\n          },\n          {\n            \"id\": 3,\n            \"description\": \"Warten\"\n          }\n        ]\n      },\n      {\n        \"name\": \"Person 2\",\n        \"description\": [\n          {\n            \"id\": 1,\n            \"description\": \"Weg finden\"\n          }\n        ],\n        \"spawnPosition\": \"P2\",\n        \"mode\": \"player\",\n        \"maxCount\": 1,\n        \"admin\": false,\n        \"level\": [\n          {\n            \"id\": 1,\n            \"description\": \"Warten\"\n          },\n          {\n            \"id\": 2,\n            \"description\": \"Erkl\u00e4ren lassen\"\n          },\n          {\n            \"id\": 3,\n            \"description\": \"Finden\"\n          }\n        ]\n      }\n    ],\n    \"EN\": [\n      {\n        \"name\": \"Person 1\",\n        \"description\": [\n          {\n            \"id\": 1,\n            \"description\": \"Rundfahrt\"\n          }\n        ],\n        \"spawnPosition\": \"P1\",\n        \"mode\": \"player\",\n        \"maxCount\": 1,\n        \"admin\": true,\n        \"level\": [\n          {\n            \"id\": 1,\n            \"description\": \"Rundfahrt\"\n          },\n          {\n            \"id\": 2,\n            \"description\": \"Erkl\u00e4ren\"\n          },\n          {\n            \"id\": 3,\n            \"description\": \"Warten\"\n          }\n        ]\n      },\n      {\n        \"name\": \"Person 2\",\n        \"description\": [\n          {\n            \"id\": 1,\n            \"description\": \"Erkl\u00e4ren lassen\"\n          }\n        ],\n        \"spawnPosition\": \"P2\",\n        \"mode\": \"player\",\n        \"maxCount\": 1,\n        \"admin\": false,\n        \"level\": [\n          {\n            \"id\": 1,\n            \"description\": \"Warten\"\n          },\n          {\n            \"id\": 2,\n            \"description\": \"Erkl\u00e4ren lassen\"\n          },\n          {\n            \"id\": 3,\n            \"description\": \"Finden\"\n          }\n        ]\n      }\n    ]\n  },\n  \"level\": [\n    {\n      \"id\": 1,\n      \"delay\": null\n    },\n    {\n      \"id\": 2,\n      \"delay\": null\n    },\n    {\n      \"id\": 3,\n      \"delay\": null\n    }\n  ],\n  \"enable\": true,\n  \"amountPlayersRequired\": 2\n}\n</code></pre>"},{"location":"getting_started/meta_avatar/","title":"Meta Avatar","text":"<p>Instead of the biq Avatars, we are using the Meta Avatar system.  The avatars have the following advantages:</p> <ul> <li>Diverse cast of pre-built avatars + customization options</li> <li>Visualisation of Hand- and Finger-Tracking</li> <li>Visualisation of Eye-Tracking</li> <li>Visualisation of Facial Expressions</li> </ul>"},{"location":"getting_started/meta_avatar/#usage","title":"Usage","text":"<p>At the moment the meta avatars are still loaded via an extra private Git project. In the next version, these will be available as a standard module of the main project.</p>"},{"location":"getting_started/meta_avatar/#references","title":"References","text":"<ul> <li>Meta Avatar Documentation</li> <li>Meta Avatar SDK</li> <li>Meta Avatar SDK Sample</li> </ul>"},{"location":"getting_started/player_controller/","title":"Player Controller","text":"<p>This documentation is work in progress.</p>"},{"location":"getting_started/setting_up/","title":"Setting Up Va.Si.Li-Lab","text":""},{"location":"getting_started/setting_up/#working-with-the-project","title":"Working with the Project","text":""},{"location":"getting_started/setting_up/#clone-the-repository","title":"Clone the Repository","text":"<p><code>git clone https://github.com/texttechnologylab/Va.Si.Li-Lab.git</code></p>"},{"location":"getting_started/setting_up/#open-the-project-with-unityhub","title":"Open the Project with UnityHub","text":"<p>Unity Hub downloads the correct Unity Version for you.  Add Android Support, if you want to build for Oculus VR Devices.</p>"},{"location":"getting_started/setting_up/#import-as-unity-package-work-in-progress","title":"Import as Unity Package (Work in Progress)","text":""},{"location":"getting_started/setting_up/#unity","title":"Unity","text":"<p>Add the git package in the Unity Package Manager <pre><code>https://github.com/texttechnologylab/Va.Si.Li-Lab.git#upm\n</code></pre></p>"},{"location":"getting_started/setting_up/#quick-start","title":"Quick-start","text":"<ol> <li>Import the samples from the Unity package and open the <code>Start</code> scene.</li> <li>Open the <code>Social Network Scene</code> prefab and configure the <code>Connection Defintion</code> in the RoomClient to point to your own Ubiq-Server installation, or for quick testing you can switch it out to the <code>Nexus Connection Definition</code> which is the server provided by the UCL (some features will be missing)</li> <li>Configure the api url to point to your server in the <code>Scene Manager</code> script located in the <code>SceneManager</code> GameObject.</li> <li>Click play!</li> </ol>"},{"location":"getting_started/setting_up/#advanced","title":"Advanced","text":"<ol> <li>Create a new scene to act as your starting scene.</li> <li>Import the <code>Player</code>, <code>Scene Selecter</code> and <code>Social Network Scene</code> prefab into your scene.</li> <li>Create another scene and add it to your build settings as well as the database.</li> <li>Click play!</li> </ol>"},{"location":"getting_started/special_scenes/","title":"Special Scenes","text":""},{"location":"getting_started/special_scenes/#metastart","title":"MetaStart","text":"<p>Starting Scene for every experiment. Here the user can select an avatar and join a scenario.</p>"},{"location":"getting_started/special_scenes/#metareturn","title":"MetaReturn","text":"<p>Helping scene, when disconnecting from a scenario. The user returns here, when he disconnects from a scenario, not to MetaStart. Some Scripts are deleted here, that otherwise would cause problems.</p>"},{"location":"getting_started/special_scenes/#start","title":"Start","text":"<p>The Starting scene, using Ubiq Avatars. Deprecated.</p>"},{"location":"getting_started/special_scenes/#tutorial","title":"Tutorial","text":"<p>Tutorial scene to get familiar with the controls. Can be started from MetaStart.</p>"},{"location":"getting_started/special_scenes/#testsceneslocalloopback-test","title":"TestScenes/LocalLoopback Test","text":"<p>Test scene for local loopback testing &gt; NetworkCapabilities.</p>"},{"location":"other/bots/","title":"Bots","text":"<p>This documentation is work in progress.</p>"},{"location":"other/experiment_visualizer_audio/","title":"Experiment Visualization Audio","text":"<p>This documentation is work in progress.</p>"},{"location":"other/replay/","title":"Replay","text":"<p>This documentation is work in progress.</p>"},{"location":"other/replay/#introduction","title":"Introduction","text":""},{"location":"other/replay/#recording-video","title":"Recording Video","text":""},{"location":"projects/digitell/","title":"DigiTeLL 2022","text":"(DigiTeLL) <p>The core of the project is the \u2018Digital Teaching and Learning Lab\u2019 (DigiTeLL), a virtual communication and collaboration space designed to enable permanent innovation loops.  In the lab, teachers or student groups will network with each other and with central support structures as part of so-called partnerships in order to implement innovative development projects in courses.  In particular, the teaching, learning and examination scenarios at Goethe University will be expanded to include digital instruments and innovative learning designs. Link</p> <p>Project Link</p>"},{"location":"projects/faces/","title":"New Data Spaces","text":"<p>New Data Spaces - DFG SPP 2431</p> <p></p>"},{"location":"projects/faces/#faces","title":"FACES","text":"<p>FACES (Feasibility, acceptance, and data quality of new multimodal surveys) is part of this SPP.</p>"},{"location":"projects/vicom/","title":"ViCom","text":"<p>ViCom (Visual Communication) - DFG Priority Programme 2392</p> <p>ViCom investigates the special features and linguistic significance of visual communication. This comprises sign languages as fully developed natural languages which exclusively rely on the visual channel for communication, but also visual means that enhance spoken language such as gestures. It aims at disclosing the specific characteristics of the visual modality as a communication channel and its interaction with other channels (especially the auditory channel) to develop a comprehensive theoretical linguistic model of human communication and its cognitive foundations.</p>"},{"location":"projects/vicom/#gemdis","title":"GeMDiS","text":"<p>GeMDiS (Virtual Reality Sustained Multimodal Distributional Semantics for Gestures in Dialogue) is part of ViCom.</p> <p></p>"},{"location":"scenarios/DGS/","title":"DGS","text":"<p>This documentation is work in progress.</p>"},{"location":"scenarios/ICIDS/","title":"ICIDS","text":"<p>This documentation is work in progress.</p>"},{"location":"scenarios/Meetingpoint/","title":"Meetingpoint","text":"<p>This documentation is work in progress.</p>"},{"location":"scenarios/OrganisationDistribution/","title":"Organisation Distribution","text":"<p>This documentation is work in progress.</p>"},{"location":"scenarios/OrganisationEducation/","title":"Organisation Education","text":"<p>This documentation is work in progress.</p>"},{"location":"scenarios/PraktikumScenario1/","title":"Praktikum Scenario 1","text":""},{"location":"scenarios/PraktikumScenario1/#description","title":"Description","text":"<p>Three people take part in the experiment. There are two runs. Run 1: One person sees the flat furnished with abstract objects. The other two The other two people have to use the descriptions to get the right objects from the storage and place them in the and place them in the right place. The participants have random restrictions (sight, hearing, nothing). After the first round, the participants can exchange ideas and tips with the restrictions and roles. restrictions and roles. Round 2: The roles and restrictions are then redistributed and the experiment is repeated.</p>"},{"location":"scenarios/PraktikumScenario1/#parameter","title":"Parameter","text":"<ul> <li>Number of participants: 3</li> <li>Duration: 2h</li> </ul>"},{"location":"scenarios/PraktikumScenario1/#rounds","title":"Rounds","text":""},{"location":"scenarios/PraktikumScenario1/#round-1","title":"Round 1","text":"<ul> <li>One person sees the flat furnished.</li> <li>The rooms are numbered on the doors (the large room in the centre has the number 8).</li> <li>The task is to describe the objects in the rooms in order so that the other people can get the right objects from the storage room and place them correctly.</li> <li>The placement does not have to be perfect. </li> <li>The round lasts 25min. Then person 3 should finish the round. (Stop the time!)</li> </ul>"},{"location":"scenarios/PraktikumScenario1/#round-2","title":"Round 2","text":"<ul> <li>All participants are allowed to exchange ideas and report on their experiences in the role and any limitations.</li> <li>The aim is to make it easier for the other participants to start the next round.</li> <li>When everyone has exchanged ideas, person 3 can start the next round.</li> </ul>"},{"location":"scenarios/PraktikumScenario1/#round-3","title":"Round 3","text":"<ul> <li>See round 1.</li> <li>The roles, restrictions and objects in the flat are redistributed randomly.</li> <li>At the end, simply close applications again and remove glasses.</li> </ul>"},{"location":"scenarios/PraktikumScenario2/","title":"Praktikum Scenario 2 - Short Films","text":""},{"location":"scenarios/PraktikumScenario2/#description","title":"Description","text":"<p>In 4 rounds, the participants are each shown a different film at the same time. After both people have seen their film (after each film),  they meet again in the living room (are automatically teleported) and are asked to give a summary of these films.</p>"},{"location":"scenarios/PraktikumScenario2/#parameter","title":"Parameter","text":"<ul> <li>Number of participants: 2</li> <li>Duration: 1h</li> </ul>"},{"location":"scenarios/PraktikumScenario2/#rounds","title":"Rounds","text":""},{"location":"scenarios/PraktikumScenario2/#round-1","title":"Round 1","text":"<ul> <li>As soon as everyone has clicked on \"Bereit\" and the round starts, they both watch their film.</li> <li>As soon as person 1 has finished the film, the level window appears and the level can be completed.</li> <li>As soon as person 2 has also finished the film, they can click on \\enquote{Ready} and person 1 can start the next round.</li> <li>If person 2 finishes the film earlier, they simply wait until the \\enquote{Ready} field appears in the level window.</li> </ul>"},{"location":"scenarios/PraktikumScenario2/#round-2","title":"Round 2","text":"<ul> <li>Both people face each other in VR and put down their controllers.</li> <li>First, person 1 narrates their film.</li> <li>After the narration, questions are welcome.</li> <li>At the end, person 1 should rate the film on a scale from 1 (bad) to 5 (good).</li> <li>Then person 2 narrates their film.</li> <li>After the narration, questions are welcome.</li> <li>Finally, person 2 should rate the film on a scale from 1 (bad) to 5 (good).</li> <li>(The ratings should later be used as a trigger to separate the two narratives)</li> <li>As soon as both people have retold their film, person 1 can end the level again (record controller for this).</li> </ul>"},{"location":"scenarios/PraktikumScenario2/#round-3","title":"Round 3","text":"<ul> <li>See round 1.</li> </ul>"},{"location":"scenarios/PraktikumScenario2/#round-4","title":"Round 4","text":"<ul> <li>See round 2.</li> </ul>"},{"location":"scenarios/PraktikumScenario2/#round-5-8","title":"Round 5-8","text":"<ul> <li>See round 1 - 4.</li> </ul>"},{"location":"scenarios/PraktikumScenario2/#movies","title":"Movies","text":""},{"location":"scenarios/PraktikumScenario2/#group-1","title":"Group 1","text":"<ul> <li>For The Birds</li> <li>Snack Attack</li> </ul>"},{"location":"scenarios/PraktikumScenario2/#group-2","title":"Group 2","text":"<ul> <li>In the Green</li> <li>Mars</li> </ul>"},{"location":"scenarios/PraktikumScenario2/#group-3","title":"Group 3","text":"<ul> <li>The Mug</li> <li>The Black Hole</li> </ul>"},{"location":"scenarios/PraktikumScenario2/#group-4","title":"Group 4","text":"<ul> <li>Dji. Death Sails</li> <li>The Choice</li> </ul>"},{"location":"scenarios/PraktikumScenario3/","title":"Praktikum Scenario 3","text":""},{"location":"scenarios/PraktikumScenario3/#description","title":"Description","text":"<p>Person 1 is driven through the fictitious SaGA city.  Person 1 then explains the route to person 2.  Person 2 then has to find their way through the SaGA city.</p>"},{"location":"scenarios/PraktikumScenario3/#parameter","title":"Parameter","text":"<ul> <li>Number of participants: 3</li> <li>Duration: 1h</li> </ul>"},{"location":"scenarios/PraktikumScenario3/#rounds","title":"Rounds","text":""},{"location":"scenarios/PraktikumScenario3/#round-1","title":"Round 1","text":"<ul> <li>Person 1 is teleported to the starting point. As soon as the round begins, the city tour starts.</li> <li>The city tour itself lasts 7 minutes.</li> <li>Person 2 can be bored in the living room during this time.</li> </ul>"},{"location":"scenarios/PraktikumScenario3/#round-2","title":"Round 2","text":"<ul> <li>Both people face each other in VR and put away their controllers.</li> <li>Person 1 now has the task of explaining the route to person 2.</li> <li>At the end, both players can pick up their controllers again.</li> <li>Player 1 finishes the level and both get ready.</li> </ul>"},{"location":"scenarios/PraktikumScenario3/#round-3","title":"Round 3","text":"<ul> <li>Person 1 starts the round and can then twiddle their thumbs.</li> <li>Person 2 is teleported to the starting point and has the task of finding the way based on the previous directions.</li> <li>As soon as person 2 is hopelessly lost, the round can be cancelled.</li> </ul>"},{"location":"scenarios/SchoolDistribution/","title":"School Distribution","text":"<p>This documentation is work in progress.</p>"},{"location":"scenarios/SchoolHetero/","title":"School Hetero","text":"<p>This documentation is work in progress.</p>"},{"location":"server/java_service/","title":"Java Room Service","text":"<p>The java service is only used to query the various available scenarios and will no longer be required in the next version.</p>"},{"location":"server/java_service/#run","title":"Run","text":"Run the Java Service (Port: 8081)<pre><code>mvn compile exec:java -Dexec.mainClass=\"org.texttechnologylab.vasillilab.VaSiLliLab\"\n</code></pre>"},{"location":"server/java_service/#unity","title":"Unity","text":"<p><code>SceneManager &gt; http://ip:8081</code></p>"},{"location":"server/mongodb/","title":"MongoDB","text":"<p>We use a MongoDB to store the experiments and the recorded data of all participants.</p>"},{"location":"server/mongodb/#installation","title":"Installation","text":""},{"location":"server/mongodb/#docker","title":"Docker","text":"<p>You can run a MongoDB instance using Docker. You should adapt all paths and logins to your needs.</p> example.yaml to create a MongoDB container<pre><code>version: '3'\nservices:\n  mongodb_container:\n    image: mongo:latest\n    container_name: vasililab_mongodb\n    hostname: mongodb\n    restart: always\n    environment:\n      MONGO_INITDB_ROOT_USERNAME: root #(1)\n      MONGO_INITDB_ROOT_PASSWORD: root\n    ports:\n      - \"27017:27017\"\n    volumes:\n      - /vol/mongoVaSiLiLab/data/:/data/db/ #(2)\n      - /vol/mongoVaSiLiLab/mongod.conf:/etc/mongod.conf\n      - /vol/mongoVaSiLiLab/log/:/var/log/mongodb/\n      - /vol/mongoVaSiLiLab/mongohome/:/home/mongodb/\n    command: [ \"-f\", \"/etc/mongod.conf\" ]\n\nvolumes:\n  mongodb_data_container:\n</code></pre> <ol> <li>Customise the data according to your needs.</li> <li>Change the directories according to your system.</li> </ol> mongod.conf<pre><code># for documentation of all options, see:\n#   http://docs.mongodb.org/manual/reference/configuration-options/\n\n# Where and how to store data.\nstorage:\n  dbPath: /data/db\n\n# where to write logging data.\nsystemLog:\n  destination: file\n  logAppend: true\n  path: /var/log/mongodb/mongod.log\n\n# network interfaces\nnet:\n  port: 27017\n  bindIp: 127.0.0.1\n\n# security\nsecurity.authorization : enabled\n</code></pre>"},{"location":"server/python_data_logger/","title":"Python Data Logger","text":"<p>Used for saving the tracking and experiment data in the MongoDB.</p> <p>Code will be available soon as part of the unified docker compose.</p> <p>Port: 5000</p>"},{"location":"server/python_data_logger/#unity","title":"Unity","text":"<p><code>MetaDataLogger &gt; http://ip:5000</code></p>"},{"location":"server/server_structure/","title":"General","text":"<p>There are currently 4 different services running in the background,  each responsible for different functions.  Not all of them are yet available as Docker images.</p> <p>For the next version, we are working on a standardised Docker Compose that automatically starts all the required services in the background.</p>"},{"location":"server/ubiq_server/","title":"Ubiq Server","text":"<p>The networking between multiple user is handled by Ubiq. (Documentation) (GitHub)</p> <pre><code>@inproceedings{friston2021ubiq,\n  title={Ubiq: A system to build flexible social virtual reality experiences},\n  author={Friston, Sebastian J and Congdon, Ben J and Swapp, David and Izzouzi, Lisa and Brandst{\\\"a}tter, Klara and Archer, Daniel and Olkkonen, Otto and Thiel, Felix Johannes and Steed, Anthony},\n  booktitle={Proceedings of the 27th ACM symposium on virtual reality software and technology},\n  pages={1--11},\n  year={2021}\n}\n</code></pre>"},{"location":"server/ubiq_server/#installation","title":"Installation","text":""},{"location":"server/ubiq_server/#docker","title":"Docker","text":"<p>We use a slightly modified version of the official Ubiq. One reason for this is that the original was not equipped with a corresponding Docker file. The other reason is that we had to add some functions to the original Ubiq. Now there is also an official docker build variant, which is why we want to integrate ubiq directly in a new version.</p> <pre><code>git clone https://github.com/texttechnologylab/ubiq.git\ncd Node\ndocker build -t ubiq .\ndocker run -p 8009:8009 ubiq\n# (docker run -d --restart unless-stopped -p 8009:8009 ubiq)\n</code></pre>"},{"location":"server/ubiq_server/#unity","title":"Unity","text":"<p><code>SocialNetworkScene &gt; RoomClient</code></p>"},{"location":"students/documentation/","title":"Writing Documentation","text":""},{"location":"students/documentation/#general","title":"General","text":"<p>This documentation is based on the MkDocs-Material framework.  It is written in Markdown and can be found in the <code>Documentation/docs</code> folder. </p>"},{"location":"students/documentation/#testing-locally","title":"Testing locally","text":""},{"location":"students/documentation/#requirements","title":"Requirements","text":"<pre><code>conda create -n mkdocs python=3.12\nconda activate mkdocs\npip install mkdocs-material \npip install mkdocs-git-revision-date-localized-plugin mkdocs-git-committers-plugin-2 mkdocs-git-authors-plugin mkdocs-glightbox\n</code></pre>"},{"location":"students/documentation/#run","title":"Run","text":"<pre><code>cd Documentation\nmkdocs serve\n</code></pre>"},{"location":"students/documentation/#adding-a-new-page","title":"Adding a new page","text":"<p>To add a new page, create a new markdown file in the <code>Documentation/docs</code> folder. Then insert the file path in the <code>mkdocs.yml</code> file under the <code>nav</code> section.</p>"}]}